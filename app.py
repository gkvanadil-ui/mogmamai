import streamlit as st
from PIL import Image, ImageEnhance
import io
import openai
import base64
import json

# 1. ì•± í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ëª¨ê·¸(Mog) AI ìŠ¤íŠœë””ì˜¤", layout="wide")

# --- API í‚¤ ì„¤ì • ---
api_key = st.secrets.get("OPENAI_API_KEY")

if not api_key:
    st.sidebar.header("âš™ï¸ AI ì„¤ì •")
    api_key = st.sidebar.text_input("OpenAI API Keyë¥¼ ë„£ì–´ì£¼ì„¸ìš”", type="password")
else:
    st.sidebar.success("âœ… ëª¨ê·¸ AI ë¹„ì„œ ì—°ê²°ë¨")

st.title("ğŸ•¯ï¸ ëª¨ê·¸(Mog) ì‘ê°€ ì „ìš© AI ë¹„ì„œ")
st.write("ì§„ì‹¬ì„ ë‹´ì€ ê¸€ê³¼ ê°ê°ì ì¸ ìƒì„¸í˜ì´ì§€ë¥¼ í•¨ê»˜ ë§Œë“­ë‹ˆë‹¤.")

st.divider()

# --- [ê³µí†µ ì…ë ¥ êµ¬ì—­] ---
with st.expander("ğŸ“¦ ì‘í’ˆ ì •ë³´ ì…ë ¥", expanded=True):
    col_in1, col_in2 = st.columns(2)
    with col_in1:
        name = st.text_input("ì œí’ˆëª…", placeholder="ì˜ˆ: ì•¤ê³¼ í‘¸ìš° ë³´ìŠ¤í„´ë°±")
        keys = st.text_area("íŠ¹ì§•/ìŠ¤í† ë¦¬", placeholder="ì˜ˆ: ì—¬í–‰ì„ ê¿ˆê¾¸ë©° ë§Œë“  ë‹¨ í•˜ë‚˜ë¿ì¸ íŒ¨ì¹˜ì›Œí¬")
    with col_in2:
        mat = st.text_input("ì†Œì¬/ì‚¬ì´ì¦ˆ", placeholder="ì˜ˆ: ìœ ëŸ½ ë¦¬ë„¨, ê°€ì£½ ì†ì¡ì´, 30x40cm")
        process = st.text_area("ì œì‘ ë””í…Œì¼", placeholder="ì˜ˆ: ì†ë°”ëŠì§ˆ ìêµ­, ì •ì„±ìŠ¤ëŸ¬ìš´ ì•ˆê° ì²˜ë¦¬")

# --- [ë©”ì¸ ê¸°ëŠ¥] íƒ­ ì¬êµ¬ì„± ---
tabs = st.tabs(["âœï¸ ê¸€ì“°ê¸° ì„¼í„°", "ğŸ¨ ì´ë¯¸ì§€ & ìƒì„¸í˜ì´ì§€", "ğŸ“± ì˜ìƒ ì œì‘ íŒ"])

# --- [Tab 1: ê¸€ì“°ê¸° ì„¼í„°] ---
with tabs[0]:
    st.subheader("ë§¤ì²´ë³„ ë§ì¶¤ íŒë§¤ê¸€")
    sub_tabs = st.tabs(["ì¸ìŠ¤íƒ€ê·¸ë¨", "ì•„ì´ë””ì–´ìŠ¤", "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´"])
    
    def generate_moog_text(platform, prompt_extra):
        if not api_key or not name:
            st.warning("ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        client = openai.OpenAI(api_key=api_key)
        full_prompt = f"""ë‹¹ì‹ ì€ ë¸Œëœë“œ 'ëª¨ê·¸'ì˜ ì‘ê°€ ë³¸ì¸ì…ë‹ˆë‹¤. [{platform}] íŒë§¤ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.
        - ë³„í‘œ(**) ê¸ˆì§€, ë‹¤ì •í•œ ë§íˆ¬(~ì´ì§€ìš”, ~í–ˆë‹µë‹ˆë‹¤), ë³¸ë¡ (ì¸ì‚¬)ë¶€í„° ì‹œì‘.
        - ì œí’ˆ:{name}, íŠ¹ì§•:{keys}, ì†Œì¬:{mat}, ë””í…Œì¼:{process}
        - {prompt_extra}"""
        with st.spinner("ì‘ê°€ë‹˜ì˜ ëª©ì†Œë¦¬ë¥¼ ë‹´ëŠ” ì¤‘..."):
            res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": full_prompt}])
            st.text_area(f"{platform} ê²°ê³¼", value=res.choices[0].message.content.replace("**", ""), height=450)

    with sub_tabs[0]:
        if st.button("ğŸª„ ì¸ìŠ¤íƒ€ìš© ìƒì„±"): generate_moog_text("ì¸ìŠ¤íƒ€ê·¸ë¨", "ì§§ê³  ê°ì„±ì ìœ¼ë¡œ, í•´ì‹œíƒœê·¸ í¬í•¨.")
    with sub_tabs[1]:
        if st.button("ğŸª„ ì•„ì´ë””ì–´ìŠ¤ìš© ìƒì„±"): generate_moog_text("ì•„ì´ë””ì–´ìŠ¤", "ëª¨ë°”ì¼ ê°€ë…ì„±ì„ ìœ„í•´ í•œ ì¤„ì— í•œ ë¬¸ì¥ì”© ì¤„ë°”ê¿ˆ í•„ìˆ˜.")
    with sub_tabs[2]:
        if st.button("ğŸª„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ìš© ìƒì„±"): generate_moog_text("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´", "êµ¬ë¶„ì„ ê³¼ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ì •ë¦¬.")

# --- [Tab 2: ì´ë¯¸ì§€ & ìƒì„¸í˜ì´ì§€] ---
with tabs[1]:
    col_img1, col_img2 = st.columns([1, 1])
    
    with col_img1:
        st.subheader("ğŸ“¸ ì§€ëŠ¥í˜• ì‚¬ì§„ ë³´ì •")
        uploaded_files = st.file_uploader("ë³´ì •í•  ì‚¬ì§„ ì„ íƒ", type=["jpg", "png"], accept_multiple_files=True)
        if uploaded_files and api_key and st.button("ğŸš€ ì‚¬ì§„ ìë™ ë³´ì •"):
            client = openai.OpenAI(api_key=api_key)
            cols = st.columns(2)
            for idx, file in enumerate(uploaded_files):
                img_bytes = file.getvalue()
                encoded = base64.b64encode(img_bytes).decode('utf-8')
                res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": [{"type": "text", "text": "í™”ì‚¬í•œ ë³´ì • ìˆ˜ì¹˜ JSON."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded}"}}]}],
                    response_format={"type": "json_object"}
                )
                vals = json.loads(res.choices[0].message.content)
                img = Image.open(io.BytesIO(img_bytes))
                img = ImageEnhance.Brightness(img).enhance(vals.get('b', 1.1))
                img = ImageEnhance.Color(img).enhance(vals.get('c', 1.1))
                with cols[idx % 2]:
                    st.image(img, use_container_width=True)

    with col_img2:
        st.subheader("ğŸ“ ìº”ë°”(Canva)ìš© ìƒì„¸í˜ì´ì§€ ì„¤ê³„")
        st.write("ì•„ë˜ ê¸°íšì•ˆì„ ë³µì‚¬í•´ì„œ ìº”ë°” í…œí”Œë¦¿ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
        if st.button("ğŸ“ ìƒì„¸í˜ì´ì§€ ì„¤ê³„ë„ ë§Œë“¤ê¸°"):
            client = openai.OpenAI(api_key=api_key)
            prompt = f"ëª¨ê·¸ ì‘ê°€ë¡œì„œ {name}ì˜ ìƒì„¸í˜ì´ì§€ 5ê°œ ì„¹ì…˜ì„ ê¸°íší•˜ì„¸ìš”. ê° í˜ì´ì§€ë³„ë¡œ 'ë©”ì¸ë¬¸êµ¬'ì™€ 'ë“¤ì–´ê°ˆ ì‚¬ì§„ ì„¤ëª…'ì„ ë³„í‘œ ì—†ì´ ê¹¨ë—í•˜ê²Œ ì§œì£¼ì„¸ìš”."
            with st.spinner("ì„¤ê³„ë„ ê·¸ë¦¬ëŠ” ì¤‘..."):
                res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}])
                st.text_area("ìº”ë°”ìš© ë ˆì‹œí”¼", value=res.choices[0].message.content.replace("**", ""), height=500)
                st.info("ğŸ’¡ Tip: ìº”ë°” í…œí”Œë¦¿ì„ ì—´ê³  ìœ„ ë¬¸êµ¬ë“¤ì„ í•˜ë‚˜ì”© ë³µì‚¬í•´ ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤!")

# --- [Tab 3: ì˜ìƒ ì œì‘ íŒ] ---
with tabs[2]:
    st.subheader("ğŸ“± ì—í”½(EPIK) ì•±ìœ¼ë¡œ ë¦´ìŠ¤ 1ë¶„ ì™„ì„±í•˜ê¸°")
    st.write("ë™ì˜ìƒ í¸ì§‘ì€ AIë³´ë‹¤ ìŠ¤ë§ˆíŠ¸í° ì•± 'ì—í”½'ì˜ í…œí”Œë¦¿ì„ ì“°ëŠ” ê²Œ ê°€ì¥ ì˜ˆë»ìš”!")
    
    st.info("""
    **ë”°ë‹˜ì´ ì•Œë ¤ì£¼ëŠ” ì—í”½ ì‚¬ìš©ë²•:**
    1. **ì—í”½(EPIK) ì•±**ì„ ì¼œê³  í•˜ë‹¨ì˜ **[í…œí”Œë¦¿]** ë©”ë‰´ë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.
    2. ê²€ìƒ‰ì°½ì— **'ìƒí’ˆí™ë³´'** ë˜ëŠ” **'ë¸Œì´ë¡œê·¸'**ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
    3. ë§ˆìŒì— ë“œëŠ” ë””ìì¸ì„ ê³¨ë¼ **[ì‚¬ìš©í•˜ê¸°]**ë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.
    4. ë³´ì •í•œ ì‚¬ì§„ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë„£ê¸°ë§Œ í•˜ë©´ ìŒì•…ê³¼ íš¨ê³¼ê°€ ìë™ìœ¼ë¡œ ì…í˜€ì§‘ë‹ˆë‹¤!
    """)
    
    st.success("ğŸ’¡ ì˜ìƒ ìë§‰ì´ ê³ ë¯¼ë  ë•ŒëŠ” 'ê¸€ì“°ê¸° ì„¼í„°' íƒ­ì—ì„œ ë§Œë“  ì¸ìŠ¤íƒ€ ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì“°ì‹œë©´ ì¢‹ì•„ìš”.")
